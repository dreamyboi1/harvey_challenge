{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa28505b",
   "metadata": {},
   "source": [
    "# Foundation of Deep Learning\n",
    "Group Challenge\n",
    "\n",
    "***\n",
    "by: Oskar Girardin (B00792974), Lasse Schmidt (B00792989)\n",
    "\n",
    "within: MS Data Sciences & Business Analytics\n",
    "\n",
    "at: CentraleSup√©lec & ESSEC Business School\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490368ee",
   "metadata": {},
   "source": [
    "### 1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a3190caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse & handle data\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchinfo import summary\n",
    "\n",
    "# evaluation metrics\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm # Progress bar\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17338ab4",
   "metadata": {},
   "source": [
    "### 2. Definition of Useful Functions (to be used in other notebooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241b8e41",
   "metadata": {},
   "source": [
    "#### 2.1 get path of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3a5ca351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notebook_path():\n",
    "    return os.path.abspath(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e35a3cf",
   "metadata": {},
   "source": [
    "#### 2.2 get class values and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e691a2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_dict(path_metadata):\n",
    "    \"\"\"\n",
    "    Get the class labels and corresponding names within a Python dict.\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    metadata: path (String) to provided metadata.json file (from downloaded data)\n",
    "    \n",
    "    Ouput\n",
    "    -----\n",
    "    class_dict: Python dict with class value as key and class label as value (e.g. 0: \"Property Roof\")\n",
    "    \"\"\"\n",
    "    # fetch metadata file\n",
    "    fin = open(path_metadata, 'r')\n",
    "    metadata = json.load(fin)\n",
    "    fin.close()\n",
    "    # create class_dict\n",
    "    class_dict = {}\n",
    "    for idx, val in enumerate(metadata[\"label:metadata\"][0][\"options\"]):\n",
    "        class_dict[idx] = val\n",
    "        \n",
    "    return class_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeeeb48",
   "metadata": {},
   "source": [
    "#### 2.3 get training & test data\n",
    "\n",
    "attention: some images are 3000x4000 others are 3072x4592!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "dcc71824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_doc_paths(X_path, y_path, notebook_path):\n",
    "    \"\"\"\n",
    "    Function that retrieves the global paths (as string )\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    X_path: string that identifies folder of input data (the .tif images in the raw folder)\n",
    "    \n",
    "    y_path: string that identifies folder of output data (.png masks are only available for training data)\n",
    "    \n",
    "    notebook_path: directory of this notebook (as string)\n",
    "    \n",
    "    \n",
    "    Output\n",
    "    -----\n",
    "    X_train_paths: Python dict of training data where each key refers to the input_path\n",
    "    \n",
    "    y_train_paths: Python dict of training data where each key refers to the output_path  \n",
    "    \n",
    "    X_test_paths: Python dict of test data where each key refers to the input_path\n",
    "    \n",
    "    \"\"\"  \n",
    "    X_train_paths, y_train_paths, X_test_paths = {}, {}, {}\n",
    "\n",
    "    for f in glob.glob(X_path + '*.tif'):\n",
    "        \n",
    "        X_filename = os.path.basename(f) # get filename (e.g. 6411.tif) of data\n",
    "        y_filename = X_filename[:-4] + '.png' # get filename of corresponding mask (e.g. 6411.png)\n",
    "        \n",
    "        key = X_filename[:-4] # key that we will insert in the dicts\n",
    "        \n",
    "        if os.path.exists(y_path + y_filename): # if this file has a mask, it's training data\n",
    "            X_train_paths[key] = X_path + X_filename\n",
    "            y_train_paths[key] = y_path + y_filename\n",
    "            \n",
    "        else: # otherwise test data\n",
    "            X_test_paths[key] = X_path + X_filename\n",
    "            \n",
    "    print(f\"Number of images for training: {len(X_train_paths)}\")\n",
    "    print(f\"Number of images for test: {len(X_test_paths)}\")\n",
    "            \n",
    "    return X_train_paths, y_train_paths, X_test_paths\n",
    "\n",
    "\n",
    "def get_data_as_np_array(paths, desired_shape):\n",
    "    \"\"\"\n",
    "    Retrieve image / mask data based on a Python dict of the corresponding paths.\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    paths: Python dict of paths of the image / mask data that should be retrieved (key is image name, value is path)\n",
    "    \n",
    "    desired_shape: tuple of int (width, height) that denotes the desired shape of the image\n",
    "    \n",
    "    \"\"\"\n",
    "    original_shape = {}\n",
    "    data = []\n",
    "    \n",
    "    for key, path in paths.items():\n",
    "        # retrieve image and save its size\n",
    "        img = Image.open(path)\n",
    "        original_shape[key] = img.size\n",
    "        \n",
    "        # if image not of desired shape, resize it\n",
    "        if img.size != desired_shape:\n",
    "            img = img.resize(desired_shape, resample = Image.Resampling.NEAREST)\n",
    "        \n",
    "        data.append(np.asarray(img)) # save image (of desired shape)\n",
    "        \n",
    "    data = np.stack(data, axis = 0) # convert list of numpy arrays into numpy array\n",
    "    \n",
    "    return original_shape, data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ee368d",
   "metadata": {},
   "source": [
    "### 3. How to run above defined functions (examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "15ecf12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_path = get_notebook_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "77a94f97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Property Roof',\n",
       " 1: 'Secondary Structure',\n",
       " 2: 'Swimming Pool',\n",
       " 3: 'Vehicle',\n",
       " 4: 'Grass',\n",
       " 5: 'Trees / Shrubs',\n",
       " 6: 'Solar Panels',\n",
       " 7: 'Chimney',\n",
       " 8: 'Street Light',\n",
       " 9: 'Window',\n",
       " 10: 'Satellite Antenna',\n",
       " 11: 'Garbage Bins',\n",
       " 12: 'Trampoline',\n",
       " 13: 'Road / Highway',\n",
       " 14: 'Under Construction / In Progress Status',\n",
       " 15: 'Power Lines & Cables',\n",
       " 16: 'Bridge',\n",
       " 17: 'Water Tank / Oil Tank',\n",
       " 18: 'Parking Area - Commercial',\n",
       " 19: 'Sports Complex / Arena',\n",
       " 20: 'Industrial Site',\n",
       " 21: 'Dense Vegetation / Forest',\n",
       " 22: 'Water Body',\n",
       " 23: 'Flooded',\n",
       " 24: 'Boat',\n",
       " 25: 'Parking Area'}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_class_dict(notebook_path + '\\Hurricane_Harvey\\\\vectors\\\\random-split-_2022_11_17-22_35_45\\CSV\\metadata.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f66a4b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_path = notebook_path + '\\Hurricane_Harvey\\\\rasters\\\\raw\\\\'\n",
    "y_path = notebook_path + '\\Hurricane_Harvey\\\\vectors\\\\random-split-_2022_11_17-22_35_45\\\\Masks\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "de01d0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images for training: 299\n",
      "Number of images for test: 75\n"
     ]
    }
   ],
   "source": [
    "X_train_paths, y_train_paths, X_test_paths = get_train_test_doc_paths(X_path, y_path, notebook_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d05dc4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_shape, data = get_data_as_np_array(X_train_paths, (400, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3d9d2c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 300, 400, 3)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
